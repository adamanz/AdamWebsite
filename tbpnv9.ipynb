{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyN5z936hCskEIMVVsWrDsEY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamanz/AdamWebsite/blob/master/tbpnv9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYQl5QLpIvDj",
        "outputId": "4850397f-24f1-4b1f-d559-836a3adb15d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies...\n",
            "Dependencies installed successfully.\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# TBPN Guest Detector\n",
        "# A tool for automatically detecting podcast guests in TBPN streams\n",
        "\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import subprocess\n",
        "import json\n",
        "import requests\n",
        "import base64\n",
        "from typing import Optional, Dict, Any, List, Tuple\n",
        "import torch\n",
        "\n",
        "# Install dependencies\n",
        "def install_dependencies():\n",
        "    print(\"Installing dependencies...\")\n",
        "    subprocess.run(\"pip install faster-whisper yt-dlp python-dotenv requests opencv-python-headless -q\", shell=True)\n",
        "    subprocess.run(\"apt-get install ffmpeg -y\", shell=True)\n",
        "    subprocess.run(\"pip install --upgrade yt-dlp -q\", shell=True)\n",
        "\n",
        "    # Import required modules after installation\n",
        "    global WhisperModel, drive\n",
        "    from faster_whisper import WhisperModel\n",
        "    from google.colab import drive, userdata\n",
        "\n",
        "    print(\"Dependencies installed successfully.\")\n",
        "\n",
        "# Set up drive mounting if needed\n",
        "def setup_drive(use_drive=True):\n",
        "    if use_drive:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        drive_output_dir = \"/content/drive/MyDrive/TBPN_Guest_Detector\"\n",
        "        os.makedirs(drive_output_dir, exist_ok=True)\n",
        "        return drive_output_dir\n",
        "    return None\n",
        "\n",
        "# Base detector class\n",
        "class BaseGuestDetector:\n",
        "    def __init__(self):\n",
        "        self.transcript_buffer = \"\"\n",
        "        self.transcript_context = []\n",
        "        self.last_processed_time = time.time()\n",
        "        self.current_timestamp = 0.0\n",
        "        self.context_window_size = 131000\n",
        "\n",
        "    def update_transcript(self, new_transcript: str, timestamp: float = 0.0):\n",
        "        self.current_timestamp = timestamp\n",
        "        self.transcript_buffer += f\"\\n{new_transcript}\"\n",
        "        self.transcript_context.append({\n",
        "            \"text\": new_transcript,\n",
        "            \"timestamp\": timestamp,\n",
        "            \"formatted_time\": self._format_timestamp(timestamp)\n",
        "        })\n",
        "        total_chars = sum(len(segment[\"text\"]) for segment in self.transcript_context)\n",
        "        if total_chars > (self.context_window_size * 4):\n",
        "            while total_chars > (self.context_window_size * 3) and self.transcript_context:\n",
        "                removed = self.transcript_context.pop(0)\n",
        "                total_chars -= len(removed[\"text\"])\n",
        "\n",
        "    def _format_timestamp(self, seconds: float) -> str:\n",
        "        hours = int(seconds // 3600)\n",
        "        minutes = int((seconds % 3600) // 60)\n",
        "        secs = int(seconds % 60)\n",
        "        return f\"{hours:02d}:{minutes:02d}:{secs:02d}\"\n",
        "\n",
        "    def _timestamp_to_seconds(self, timestamp_str: str) -> float:\n",
        "        try:\n",
        "            h, m, s = map(int, timestamp_str.split(':'))\n",
        "            return h * 3600 + m * 60 + s\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "    def _find_context_for_timestamp(self, timestamp: float) -> str:\n",
        "        nearby_segments = []\n",
        "        for segment in self.transcript_context:\n",
        "            if abs(segment[\"timestamp\"] - timestamp) < 30:\n",
        "                nearby_segments.append(segment[\"text\"])\n",
        "        return \" \".join(nearby_segments) if nearby_segments else self.transcript_buffer[-500:]\n",
        "\n",
        "    def _prepare_transcript_for_analysis(self) -> str:\n",
        "        formatted_transcript = \"\"\n",
        "        intro_keywords = [\"guest\", \"joining\", \"welcome\", \"introduce\", \"with us\", \"today we have\", \"speaking with\"]\n",
        "        for segment in self.transcript_context:\n",
        "            time_str = segment[\"formatted_time\"]\n",
        "            text = segment[\"text\"].strip()\n",
        "            contains_intro = any(keyword in text.lower() for keyword in intro_keywords)\n",
        "            if contains_intro:\n",
        "                formatted_transcript += f\"[TIMESTAMP: {time_str}] ðŸ” {text}\\n\\n\"\n",
        "            else:\n",
        "                formatted_transcript += f\"[TIMESTAMP: {time_str}] {text}\\n\"\n",
        "        return formatted_transcript\n",
        "\n",
        "    def _parse_structured_response(self, text: str) -> List[Dict[str, Any]]:\n",
        "        if \"NO_GUESTS_DETECTED\" in text:\n",
        "            return []\n",
        "        guest_pattern = r\"GUEST: (.*?) \\| HANDLE: (.*?) \\| TIMESTAMP: (.*?) \\| CONFIDENCE: (\\d+)\"\n",
        "        matches = re.findall(guest_pattern, text)\n",
        "        guests = []\n",
        "        for match in matches:\n",
        "            name = match[0].strip()\n",
        "            handle = match[1].strip()\n",
        "            timestamp_str = match[2].strip()\n",
        "            confidence = int(match[3])\n",
        "            if confidence >= 7:\n",
        "                timestamp = self._timestamp_to_seconds(timestamp_str)\n",
        "                context = self._find_context_for_timestamp(timestamp)\n",
        "                if handle == \"Not mentioned\":\n",
        "                    handle_match = re.search(r'@(\\w+)', context, re.IGNORECASE)\n",
        "                    if handle_match:\n",
        "                        handle = handle_match.group(1)\n",
        "                guests.append({\n",
        "                    \"name\": name,\n",
        "                    \"x_handle\": handle,\n",
        "                    \"timestamp\": timestamp,\n",
        "                    \"formatted_time\": timestamp_str,\n",
        "                    \"confidence\": confidence,\n",
        "                    \"context\": context\n",
        "                })\n",
        "        return guests\n",
        "\n",
        "# GeminiGuestDetector class\n",
        "class GeminiGuestDetector(BaseGuestDetector):\n",
        "    def __init__(self, api_key: str, endpoint: str = \"https://generativelanguage.googleapis.com/v1beta\", model: str = \"gemini-2.5-flash-preview-04-17\"):\n",
        "        super().__init__()\n",
        "        self.api_key = api_key\n",
        "        self.endpoint = endpoint\n",
        "        self.model = model\n",
        "        self.headers = {\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "\n",
        "    def detect_guests(self) -> List[Dict[str, Any]]:\n",
        "        if not self.transcript_context:\n",
        "            return []\n",
        "        formatted_transcript = self._prepare_transcript_for_analysis()\n",
        "        content = {\n",
        "            \"parts\": [\n",
        "                {\n",
        "                    \"text\": (\n",
        "                        \"You are an AI specialized in podcast guest detection for TBPN. \"\n",
        "                        \"Analyze the transcript to identify all guests introduced in the show. Focus on phrases like \"\n",
        "                        \"'joining us today', 'our guest is', 'welcome to the show', 'with us is', or 'today we have'. \"\n",
        "                        \"Extract: 1. Full name, 2. X handle (if mentioned), 3. Timestamp of first appearance, \"\n",
        "                        \"4. Confidence level (0-10). Format response as: \"\n",
        "                        \"GUEST: [name] | HANDLE: [X handle or 'Not mentioned'] | TIMESTAMP: [HH:MM:SS] | CONFIDENCE: [0-10]\\n\"\n",
        "                        \"Return 'NO_GUESTS_DETECTED' if no guests are found. Example: \"\n",
        "                        \"GUEST: John Doe | HANDLE: @JohnDoe | TIMESTAMP: 00:05:30 | CONFIDENCE: 9\\n\\n\"\n",
        "                        \"Analyze this podcast transcript and detect all guests mentioned. Here's the transcript with timestamps:\\n\\n\"\n",
        "                        + formatted_transcript\n",
        "                    )\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "        try:\n",
        "            url = f\"{self.endpoint}/models/{self.model}:generateContent?key={self.api_key}\"\n",
        "            payload = {\n",
        "                \"contents\": [content],\n",
        "                \"generationConfig\": {\n",
        "                    \"temperature\": 0.3,\n",
        "                    \"maxOutputTokens\": 2000\n",
        "                }\n",
        "            }\n",
        "            response = requests.post(url, headers=self.headers, json=payload, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            result = response.json().get(\"candidates\", [{}])[0].get(\"content\", {}).get(\"parts\", [{}])[0].get(\"text\", \"\")\n",
        "            return self._parse_structured_response(result)\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"Gemini API request failed: {e}\")\n",
        "            return []\n",
        "\n",
        "    def analyze_video_clip(self, video_path: str, prompt: str) -> str:\n",
        "        with open(video_path, \"rb\") as video_file:\n",
        "            video_data = base64.b64encode(video_file.read()).decode('utf-8')\n",
        "        content = {\n",
        "            \"parts\": [\n",
        "                {\n",
        "                    \"text\": prompt\n",
        "                },\n",
        "                {\n",
        "                    \"inline_data\": {\n",
        "                        \"mime_type\": \"video/mp4\",\n",
        "                        \"data\": video_data\n",
        "                    }\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "        payload = {\n",
        "            \"contents\": [content],\n",
        "            \"generationConfig\": {\n",
        "                \"temperature\": 0.3,\n",
        "                \"maxOutputTokens\": 1000\n",
        "            }\n",
        "        }\n",
        "        try:\n",
        "            url = f\"{self.endpoint}/models/{self.model}:generateContent?key={self.api_key}\"\n",
        "            response = requests.post(url, headers=self.headers, json=payload, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            result = response.json().get(\"candidates\", [{}])[0].get(\"content\", {}).get(\"parts\", [{}])[0].get(\"text\", \"\")\n",
        "            return result\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"Gemini API video analysis failed: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "# Main TBPN Guest Detector class\n",
        "class TBPNGuestDetector:\n",
        "    def __init__(self, video_url: Optional[str] = None,\n",
        "                 channel_url: str = \"https://www.youtube.com/@TBPNLive/streams\",\n",
        "                 output_dir: str = \"/content/output\",\n",
        "                 whisper_model: str = \"large-v3\",\n",
        "                 device: str = \"cuda\",\n",
        "                 use_gemini: bool = True,\n",
        "                 gemini_api_key: Optional[str] = None,\n",
        "                 use_drive: bool = False,\n",
        "                 drive_output_dir: Optional[str] = None,\n",
        "                 use_video_analysis: bool = True):\n",
        "        self.video_url = video_url\n",
        "        self.channel_url = channel_url\n",
        "        self.output_dir = drive_output_dir if use_drive else output_dir\n",
        "        self.whisper_model_name = whisper_model\n",
        "        self.device = device\n",
        "        self.compute_type = \"int8\" if device == \"cpu\" else \"float16\"\n",
        "        self.use_gemini = use_gemini\n",
        "        self.use_drive = use_drive\n",
        "        self.drive_output_dir = drive_output_dir\n",
        "        self.use_video_analysis = use_video_analysis\n",
        "        self.gemini_detector = None\n",
        "\n",
        "        if use_gemini:\n",
        "            if not gemini_api_key:\n",
        "                raise ValueError(\"Gemini API key is required when use_gemini is True\")\n",
        "            self.gemini_detector = GeminiGuestDetector(api_key=gemini_api_key)\n",
        "\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "        self.video_path = None\n",
        "        self.audio_path = None\n",
        "        self.transcript_path = None\n",
        "        self.video_title = \"Unknown_Title\"\n",
        "        self.video_id = None\n",
        "        self.transcript_buffer = \"\"\n",
        "\n",
        "    def _sanitize_filename(self, name: str) -> str:\n",
        "        name = re.sub(r'[^\\w\\s-]', '', name)\n",
        "        name = name.strip().replace(' ', '_')\n",
        "        return name\n",
        "\n",
        "    def get_video_info(self, target_url: str) -> Dict[str, str]:\n",
        "        info_cmd = ['yt-dlp', '-j', '--skip-download', target_url, '--playlist-end', '1']\n",
        "        try:\n",
        "            info_result = subprocess.run(info_cmd, capture_output=True, text=True, check=True)\n",
        "            info = json.loads(info_result.stdout)\n",
        "            return {\n",
        "                'title': info.get('title', 'Unknown_Title'),\n",
        "                'id': info.get('id', 'unknown_id')\n",
        "            }\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            raise Exception(f\"Failed to get video info: {e.stderr}\")\n",
        "\n",
        "    def download_video(self, target_url: str):\n",
        "        cmd = ['yt-dlp', '-f', 'best', '--playlist-end', '1', '-o', self.video_path, target_url]\n",
        "        try:\n",
        "            subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
        "            if not os.path.exists(self.video_path):\n",
        "                raise Exception(\"Video download failed - file does not exist\")\n",
        "            print(f\"Downloaded video to: {self.video_path}\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            raise Exception(f\"Failed to download video: {e.stderr}\")\n",
        "\n",
        "    def extract_audio(self):\n",
        "        print(\"Extracting audio...\")\n",
        "        cmd = ['ffmpeg', '-i', self.video_path, '-vn', '-acodec', 'libmp3lame', '-ar', '16000', '-ac', '1', '-y', self.audio_path]\n",
        "        try:\n",
        "            subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "            print(f\"Audio extracted to: {self.audio_path}\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            raise Exception(f\"Failed to extract audio: {e.stderr}\")\n",
        "\n",
        "    def transcribe_audio(self) -> List[Dict[str, Any]]:\n",
        "        print(f\"Transcribing audio using {self.whisper_model_name} model on {self.device}...\")\n",
        "        try:\n",
        "            from faster_whisper import WhisperModel\n",
        "            model = WhisperModel(\n",
        "                self.whisper_model_name,\n",
        "                device=self.device,\n",
        "                compute_type=self.compute_type,\n",
        "                download_root=\"/tmp/whisper-models\"\n",
        "            )\n",
        "            segments, _ = model.transcribe(\n",
        "                self.audio_path,\n",
        "                beam_size=5,\n",
        "                language=\"en\",\n",
        "                vad_filter=True,\n",
        "                vad_parameters=dict(min_silence_duration_ms=500)\n",
        "            )\n",
        "            transcript = []\n",
        "            for seg in segments:\n",
        "                segment = {\n",
        "                    'start': seg.start,\n",
        "                    'end': seg.end,\n",
        "                    'text': seg.text.strip(),\n",
        "                }\n",
        "                self.transcript_buffer += f\" {seg.text}\"\n",
        "                if self.gemini_detector:\n",
        "                    self.gemini_detector.update_transcript(seg.text, seg.start)\n",
        "                transcript.append(segment)\n",
        "            with open(self.transcript_path, 'w') as f:\n",
        "                json.dump(transcript, f, indent=2)\n",
        "            print(f\"Transcription complete. {len(transcript)} segments saved to {self.transcript_path}\")\n",
        "            return transcript\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Transcription failed: {str(e)}\")\n",
        "\n",
        "    def extract_video_clip(self, timestamp: float, duration: float = 60.0, output_path: str = None) -> str:\n",
        "        if not output_path:\n",
        "            sanitized_name = self._sanitize_filename(f\"clip_{int(timestamp)}\")\n",
        "            output_path = os.path.join(self.output_dir, f\"{sanitized_name}_clip.mp4\")\n",
        "        cmd = [\n",
        "            'ffmpeg', '-y', '-ss', str(timestamp), '-i', self.video_path,\n",
        "            '-t', str(duration), '-c:v', 'libx264', '-c:a', 'aac', output_path\n",
        "        ]\n",
        "        try:\n",
        "            subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "            print(f\"Video clip saved to {output_path}\")\n",
        "            return output_path\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"Failed to extract video clip: {e.stderr}\")\n",
        "            return \"\"\n",
        "\n",
        "    def take_screenshot(self, timestamp: float, output_path: str):\n",
        "        cmd = ['ffmpeg', '-ss', str(timestamp), '-i', self.video_path, '-frames:v', '1', '-q:v', '2', output_path]\n",
        "        try:\n",
        "            subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "            print(f\"Screenshot saved to {output_path}\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"Failed to take screenshot: {e.stderr}\")\n",
        "\n",
        "    def detect_guests(self) -> List[Dict[str, Any]]:\n",
        "        print(\"Analyzing transcript to detect guests...\")\n",
        "        all_results = []\n",
        "        if self.use_gemini and self.gemini_detector:\n",
        "            gemini_guests = self.gemini_detector.detect_guests()\n",
        "            if gemini_guests:\n",
        "                all_results.append({\n",
        "                    \"detector\": \"gemini\",\n",
        "                    \"guests\": gemini_guests,\n",
        "                    \"detection_method\": \"gemini\"\n",
        "                })\n",
        "                print(f\"\\nDetected {len(gemini_guests)} guest(s) with Gemini AI:\")\n",
        "                for i, guest in enumerate(gemini_guests, 1):\n",
        "                    print(f\"  Guest {i}:\")\n",
        "                    print(f\"    Name: {guest['name']}\")\n",
        "                    print(f\"    X Handle: {guest['x_handle']}\")\n",
        "                    print(f\"    Time: {guest['formatted_time']}\")\n",
        "                    print(f\"    Confidence: {guest['confidence']}/10\")\n",
        "            else:\n",
        "                print(\"No guests detected by Gemini AI.\")\n",
        "\n",
        "        if not all_results:\n",
        "            print(\"No guests detected by LLMs. Falling back to regex-based detection...\")\n",
        "            regex_results = self._regex_detect_guests()\n",
        "            all_results.append(regex_results)\n",
        "\n",
        "        return all_results\n",
        "\n",
        "    def _regex_detect_guests(self) -> Dict[str, Any]:\n",
        "        introduction_patterns = [\n",
        "            r\"(?:our|my|today'?s|special|joining us|welcome|with us|have|introduces?) guest(?:s)? (?:today |tonight |is |are |)(?:is |are |)([\\w\\s\\-''\\.]+?)(?:,|\\.|!|$)\",\n",
        "            r\"(?:joining|welcome|with) (?:us|me) (?:today|tonight|now|is|are) ([\\w\\s\\-''\\.]+?)(?:,|\\.|!|$)\",\n",
        "            r\"(?:I'?m|we'?re) (?:joined|talking|speaking) (?:by|with) ([\\w\\s\\-''\\.]+?)(?:,|\\.|!|$)\",\n",
        "            r\"(?:I|we) have ([\\w\\s\\-''\\.]+?) (?:joining|with) (?:us|me)(?:,|\\.|!|$)\"\n",
        "        ]\n",
        "        handle_patterns = [\n",
        "            r\"@(\\w+)\",\n",
        "            r\"(?:on|at) (?:Twitter|X|twitter|x) (?:as |at |)@?(\\w+)\",\n",
        "            r\"(?:Twitter|X|twitter|x) handle (?:is |)@?(\\w+)\",\n",
        "            r\"(?:Twitter|X|twitter|x) @?(\\w+)\"\n",
        "        ]\n",
        "        guests = []\n",
        "        guest_names = set()\n",
        "        transcript = self.transcript_buffer\n",
        "        for pattern in introduction_patterns:\n",
        "            matches = re.finditer(pattern, transcript, re.IGNORECASE)\n",
        "            for match in matches:\n",
        "                name = match.group(1).strip()\n",
        "                if len(name.split()) >= 2 and len(name) < 50:\n",
        "                    if not any(self._name_similarity(name, existing) > 0.8 for existing in guest_names):\n",
        "                        guest_names.add(name)\n",
        "                        context_start = max(0, match.start() - 200)\n",
        "                        context_end = min(len(transcript), match.end() + 200)\n",
        "                        context = transcript[context_start:context_end]\n",
        "                        x_handle = \"Not mentioned\"\n",
        "                        for handle_pattern in handle_patterns:\n",
        "                            handle_match = re.search(handle_pattern, context, re.IGNORECASE)\n",
        "                            if handle_match:\n",
        "                                x_handle = handle_match.group(1)\n",
        "                                break\n",
        "                        timestamp, formatted_time = self._find_timestamp_for_text(match.group(0))\n",
        "                        guests.append({\n",
        "                            \"name\": name,\n",
        "                            \"x_handle\": x_handle,\n",
        "                            \"confidence\": self._calculate_confidence(name, x_handle),\n",
        "                            \"context\": context,\n",
        "                            \"timestamp\": timestamp,\n",
        "                            \"formatted_time\": formatted_time\n",
        "                        })\n",
        "        guests = [g for g in guests if g[\"confidence\"] >= 7]\n",
        "        guests.sort(key=lambda g: g[\"confidence\"], reverse=True)\n",
        "        result = {\n",
        "            \"detector\": \"regex\",\n",
        "            \"total_guests_detected\": len(guests),\n",
        "            \"guests\": guests,\n",
        "            \"detection_method\": \"regex\"\n",
        "        }\n",
        "        if guests:\n",
        "            print(f\"\\nDetected {len(guests)} guest(s) with regex:\")\n",
        "            for i, guest in enumerate(guests, 1):\n",
        "                print(f\"  Guest {i}:\")\n",
        "                print(f\"    Name: {guest['name']}\")\n",
        "                print(f\"    X Handle: {guest['x_handle']}\")\n",
        "                print(f\"    Time: {guest['formatted_time']}\")\n",
        "                print(f\"    Confidence: {guest['confidence']}/10\")\n",
        "        else:\n",
        "            print(\"No guests detected with regex.\")\n",
        "        return result\n",
        "\n",
        "    def _name_similarity(self, name1: str, name2: str) -> float:\n",
        "        name1, name2 = name1.lower(), name2.lower()\n",
        "        if name1 in name2 or name2 in name1:\n",
        "            return 0.9\n",
        "        words1, words2 = set(name1.split()), set(name2.split())\n",
        "        if not words1 or not words2:\n",
        "            return 0\n",
        "        matching = len(words1.intersection(words2))\n",
        "        total = len(words1.union(words2))\n",
        "        return matching / total\n",
        "\n",
        "    def _calculate_confidence(self, name: str, x_handle: str) -> int:\n",
        "        score = 0\n",
        "        if name:\n",
        "            score += 3 if len(name.split()) >= 2 else 1\n",
        "            score += 2 if 5 <= len(name) <= 40 else 0\n",
        "        if x_handle and x_handle != \"Not mentioned\":\n",
        "            score += 3\n",
        "            score += 1 if 3 <= len(x_handle) <= 15 and x_handle.isalnum() else 0\n",
        "        if \"our guest\" in self.transcript_buffer.lower() or \"joining us\" in self.transcript_buffer.lower():\n",
        "            score += 1\n",
        "        return min(score, 10)\n",
        "\n",
        "    def _find_timestamp_for_text(self, text: str) -> Tuple[float, str]:\n",
        "        if not os.path.exists(self.transcript_path):\n",
        "            return 0.0, \"00:00:00\"\n",
        "        with open(self.transcript_path, 'r') as f:\n",
        "            transcript = json.load(f)\n",
        "        timestamp, formatted_time = 0.0, \"00:00:00\"\n",
        "        simple_text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
        "        for segment in transcript:\n",
        "            segment_text = segment.get('text', '')\n",
        "            simple_segment = re.sub(r'[^\\w\\s]', '', segment_text.lower())\n",
        "            if simple_text in simple_segment:\n",
        "                timestamp = segment.get('start', 0.0)\n",
        "                formatted_time = self._format_timestamp(timestamp)\n",
        "                break\n",
        "            words = simple_text.split()\n",
        "            segment_words = simple_segment.split()\n",
        "            matches = sum(1 for word in words if word in segment_words)\n",
        "            if matches >= min(3, len(words)):\n",
        "                timestamp = segment.get('start', 0.0)\n",
        "                formatted_time = self._format_timestamp(timestamp)\n",
        "                break\n",
        "        return timestamp, formatted_time\n",
        "\n",
        "    def _format_timestamp(self, seconds: float) -> str:\n",
        "        hours = int(seconds // 3600)\n",
        "        minutes = int((seconds % 3600) // 60)\n",
        "        secs = int(seconds % 60)\n",
        "        return f\"{hours:02d}:{minutes:02d}:{secs:02d}\"\n",
        "\n",
        "    def run_pipeline(self, cleanup: bool = True) -> Dict[str, Any]:\n",
        "        try:\n",
        "            target_url = self.video_url if self.video_url else self.channel_url\n",
        "            video_info = self.get_video_info(target_url)\n",
        "            self.video_title = video_info['title']\n",
        "            self.video_id = video_info['id']\n",
        "            sanitized_title = self._sanitize_filename(self.video_title)\n",
        "            sanitized_id = self._sanitize_filename(self.video_id)\n",
        "\n",
        "            # Create directory structure\n",
        "            main_folder = os.path.join(self.output_dir, f\"{sanitized_title}_{sanitized_id}\")\n",
        "            video_audio_dir = os.path.join(main_folder, \"Video_and_Audio\")\n",
        "            text_output_dir = os.path.join(main_folder, \"Text_Output\")\n",
        "            screenshots_dir = os.path.join(main_folder, \"Screenshots\")\n",
        "            clips_dir = os.path.join(main_folder, \"Clips\")\n",
        "\n",
        "            for dir_path in [video_audio_dir, text_output_dir, screenshots_dir, clips_dir]:\n",
        "                os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "            self.video_path = os.path.join(video_audio_dir, f\"{sanitized_title}_video.mp4\")\n",
        "            self.audio_path = os.path.join(video_audio_dir, f\"{sanitized_title}_audio.mp3\")\n",
        "            self.transcript_path = os.path.join(text_output_dir, f\"{sanitized_title}_transcript.json\")\n",
        "\n",
        "            # Run the pipeline steps\n",
        "            self.download_video(target_url)\n",
        "            self.extract_audio()\n",
        "            self.transcribe_audio()\n",
        "            results = self.detect_guests()\n",
        "\n",
        "            processed_results = {\"detectors\": []}\n",
        "            for detector_result in results:\n",
        "                detector_name = detector_result[\"detector\"]\n",
        "                guests = detector_result[\"guests\"]\n",
        "\n",
        "                # Video analysis for guest handles\n",
        "                if guests and self.use_video_analysis and self.gemini_detector:\n",
        "                    for guest in guests:\n",
        "                        sanitized_name = self._sanitize_filename(guest['name'])\n",
        "                        clip_path = self.extract_video_clip(\n",
        "                            guest['timestamp'],\n",
        "                            output_path=os.path.join(clips_dir, f\"{sanitized_name}_{guest['formatted_time'].replace(':', '_')}_clip.mp4\")\n",
        "                        )\n",
        "                        if clip_path:\n",
        "                            prompt = f\"Extract the guest's X handle from this 1-minute video clip. Look for text like '@username'. Return in the format: 'Handle: @username' or 'Handle: Not found'.\"\n",
        "                            response = self.gemini_detector.analyze_video_clip(clip_path, prompt)\n",
        "                            handle_match = re.search(r\"Handle: @(\\w+)\", response)\n",
        "                            guest[\"handle_from_video\"] = handle_match.group(1) if handle_match else \"Not found\"\n",
        "                            if cleanup and os.path.exists(clip_path):\n",
        "                                os.remove(clip_path)\n",
        "                        else:\n",
        "                            guest[\"handle_from_video\"] = \"Clip extraction failed\"\n",
        "\n",
        "                processed_results[\"detectors\"].append({\n",
        "                    \"detector\": detector_name,\n",
        "                    \"total_guests_detected\": len(guests),\n",
        "                    \"guests\": guests,\n",
        "                    \"detection_method\": detector_result[\"detection_method\"]\n",
        "                })\n",
        "\n",
        "            # Save results\n",
        "            output_path = os.path.join(text_output_dir, f\"{sanitized_title}_guest_results.json\")\n",
        "            with open(output_path, 'w') as f:\n",
        "                json.dump(processed_results, f, indent=2)\n",
        "            print(f\"Results saved to {output_path}\")\n",
        "\n",
        "            # Cleanup if requested\n",
        "            if cleanup:\n",
        "                print(\"Cleaning up temporary files...\")\n",
        "                if os.path.exists(self.video_path):\n",
        "                    os.remove(self.video_path)\n",
        "                if os.path.exists(self.audio_path):\n",
        "                    os.remove(self.audio_path)\n",
        "\n",
        "            return processed_results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in pipeline: {str(e)}\")\n",
        "            return {\"error\": str(e), \"detectors\": []}\n",
        "\n",
        "def main():\n",
        "    # Install dependencies first\n",
        "    install_dependencies()\n",
        "\n",
        "    # Get secrets from Colab\n",
        "    from google.colab import userdata\n",
        "\n",
        "    gemini_api_key = userdata.get('GEMINI_API_KEY')\n",
        "    if not gemini_api_key:\n",
        "        raise ValueError(\"Gemini API key not found in secrets. Add it as 'GEMINI_API_KEY'.\")\n",
        "\n",
        "    # Determine if we're using Google Drive\n",
        "    use_drive = True\n",
        "    drive_output_dir = setup_drive(use_drive) if use_drive else None\n",
        "\n",
        "    # Check for CUDA\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Initialize detector\n",
        "    detector = TBPNGuestDetector(\n",
        "        video_url=\"https://www.youtube.com/watch?v=dIcfh1rDAsE\",  # Replace with your target video\n",
        "        channel_url=\"https://www.youtube.com/@TBPNLive/streams\",\n",
        "        output_dir=\"/content/output\",\n",
        "        whisper_model=\"large-v3\",\n",
        "        device=device,\n",
        "        use_gemini=True,\n",
        "        gemini_api_key=gemini_api_key,\n",
        "        use_drive=use_drive,\n",
        "        drive_output_dir=drive_output_dir,\n",
        "        use_video_analysis=True\n",
        "    )\n",
        "\n",
        "    # Run pipeline\n",
        "    results = detector.run_pipeline(cleanup=True)\n",
        "\n",
        "    # Display summary\n",
        "    print(\"\\nPipeline completed!\")\n",
        "    if use_drive:\n",
        "        print(f\"Outputs saved to Google Drive: {detector.output_dir}\")\n",
        "    else:\n",
        "        print(\"Files saved to local Colab environment.\")\n",
        "\n",
        "    # Print detected guests\n",
        "    for detector_result in results.get(\"detectors\", []):\n",
        "        detector_name = detector_result[\"detector\"]\n",
        "        guests = detector_result[\"guests\"]\n",
        "        if guests:\n",
        "            print(f\"\\nDetected {len(guests)} guest(s) with {detector_name}:\")\n",
        "            for i, guest in enumerate(guests, 1):\n",
        "                print(f\"  Guest {i}:\")\n",
        "                print(f\"    Name: {guest['name']}\")\n",
        "                print(f\"    X Handle: {guest['x_handle']}\")\n",
        "                print(f\"    Handle from Video: {guest.get('handle_from_video', 'N/A')}\")\n",
        "                print(f\"    Time: {guest['formatted_time']}\")\n",
        "                print(f\"    Confidence: {guest['confidence']}/10\")\n",
        "        else:\n",
        "            print(f\"No guests detected with {detector_name}.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}